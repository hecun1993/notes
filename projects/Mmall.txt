支付宝相关文档

沙箱登录：https://openhome.alipay.com/platform/appDaily.htm 
沙箱环境使用说明：https://doc.open.alipay.com/doc2/detail.htm?treeId=200&articleId=105311&docType=1 
如何使用沙箱环境：https://support.open.alipay.com/support/hotProblemDetail.htm?spm=a219a.7386793.0.0.uS5uZ6&id=251932&tagId=100248 
当面付产品介绍：https://doc.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.hV5Clx&treeId=193&articleId=105072&docType=1 
扫码支付接入指引：https://doc.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.Ia6Wqy&treeId=193&articleId=106078&docType=1 
当面付快速接入：https://doc.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.bROnXf&treeId=193&articleId=105170&docType=1 
当面付接入必读：https://doc.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.hV5Clx&treeId=193&articleId=105322&docType=1 
当面付进阶功能：https://doc.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.YFmkxI&treeId=193&articleId=105190&docType=1 
当面付异步通知-仅用于扫码支付：https://doc.open.alipay.com/docs/doc.htm?spm=a219a.7629140.0.0.BykVSR&treeId=193&articleId=103296&docType=1 
当面付SDK&DEMO：https://support.open.alipay.com/docs/doc.htm?spm=a219a.7386797.0.0.k0rwWc&treeId=193&articleId=105201&docType=1 
服务端SDK：https://doc.open.alipay.com/doc2/detail?treeId=54&articleId=103419&docType=1 
生成RSA密钥：https://doc.open.alipay.com/docs/doc.htm?treeId=291&articleId=105971&docType=1 
线上创建应用说明：https://doc.open.alipay.com/doc2/detail.htm?treeId=200&articleId=105310&docType=1#s0 

回调: 支付宝调用我们的接口, 然后携带一些和交易状态有关的参数, 我们的接口需要接收这些参数来得知交易的状态, 然后做自己的业务逻辑处理, 比如跳转到订单详情页等. 

扫码之后
付款之后
支付宝总共有两次回调

验证回调的正确性(验签, 回调是否来自支付宝)

useradd -d /usr/geely -m geely
passwd geely

vim /etc/sudoers
查找root, 在下方给geely加一样的sudo权限

自动化发布脚本:

echo "===========进入git项目happymmall目录============="
cd /developer/git-repository/mmall

echo "==========git切换分之到mmall-v1.0==============="
git checkout mmall-v1.0

echo "==================git fetch======================"
git fetch

echo "==================git pull======================"
git pull

echo "===========编译并跳过单元测试===================="
mvn clean package -Dmaven.test.skip=true

echo "============删除旧的ROOT.war==================="
rm /developer/apache-tomcat-7.0.73/webapps/ROOT.war

echo "======拷贝编译出来的war包到tomcat下-ROOT.war======="
cp /developer/git-repository/mmall/target/mmall.war  /developer/apache-tomcat-7.0.73/webapps/ROOT.war

echo "============删除tomcat下旧的ROOT文件夹============="
rm -rf /developer/apache-tomcat-7.0.73/webapps/ROOT

echo "====================关闭tomcat====================="
/developer/apache-tomcat-7.0.73/bin/shutdown.sh

echo "================sleep 10s========================="
for i in {1..10}
do
	echo $i"s"
	sleep 1s
done

echo "====================启动tomcat====================="
/developer/apache-tomcat-7.0.73/bin/startup.sh

maven环境隔离

1. 在pom.xml文件中配置
<build>
	<resources>
	          <resource>
	         		<directory>src/main/resources.${deploy.type}</directory>
	              	<excludes>
	                  		<exclude>*.jsp</exclude>
	              	</excludes>
	         </resource>
	         <resource>
	             	<directory>src/main/resources</directory>
	         </resource>
	</resources>

	<plugins></plugins>
</build>

<profiles>
        <profile>
            <id>dev</id>
            <activation>
                <activeByDefault>true</activeByDefault>
            </activation>
            <properties>
                <deploy.type>dev</deploy.type>
            </properties>
        </profile>
        <profile>
            <id>beta</id>
            <properties>
                <deploy.type>beta</deploy.type>
            </properties>
        </profile>
        <profile>
            <id>prod</id>
            <properties>
                <deploy.type>prod</deploy.type>
            </properties>
        </profile>
 </profiles>

 2. 在resources下建立resources.beta/dev/prod, 把各自环境中的配置信息文件放入各自文件夹之中. 比如datasource.properties, logback.xml, mmall.properties, zfbinfo.properties

 3. 启动

 mvn clean package -Dmaven.skip.test=true -Pdev
 打包一个dev环境的war包

 单机部署多个tomcat

 修改/etc/profile, 增加tomcat环境变量

 export CATALINA_BASE=${tomcat1's path}
 export CATALINA_HOME=${tomcat1's path}
 export TOMCAT_HOME=${tomcat1's path}
 export CATALINA_2_BASE=${tomcat2's path}
 export CATALINA_2_HOME=${tomcat2's path}
 export TOMCAT_2_HOME=${tomcat2's path}

 第一个tomcat不变
 第二个tomcat, 打开catalina.sh, 找到# OS specific..., 在这行下面添加配置
 export CATALINA_BASE=$CATALINA_2_BASE
 export CATALINA_HOME=$CATALINA_2_HOME
 再打开server.xml, 修改三个端口, 比第一个tomcat都加1000
 server port; connector port; connector port

 然后就可以分别启动两个tomcat了


nginx

轮询
权重
ip hash(同一个用户访问同一台机器)
url hash(同一个服务访问同一台机器)
fair(后端服务器响应时间短的优先分配)

upstream www.happymmall.com {
	server 127.0.0.1:8080;
	server 127.0.0.1:9080;

	server 127.0.0.1:8080 weight=15;
	server 127.0.0.1:9080 weight=10;

	ip_hash;
	server 127.0.0.1:8080 weight=15;
	server 127.0.0.1:9080 weight=10;

	server 127.0.0.1:8080 weight=15;
	server 127.0.0.1:9080 weight=10;
	hash $request_uri;

	server 127.0.0.1:8080 weight=15;
	server 127.0.0.1:9080 weight=10;
	fair;
}

使用tomcat + nginx搭建集群

启动两个tomcat
修改hosts文件
	127.0.0.1 www.imooc.com

启动nginx, 默认安装路径是/usr/local/nginx/sbin/nginx.sh
编辑nginx/conf/nginx.conf, 在http节点下增加
include vhosts/*.conf;
增加www.imooc.com.conf

upstream www.imooc.com {
	server www.imooc.com:8080 weight=1;
	server www.imooc.com:9080 weight=1;
}

server {
	listen 80;
	autoindex on;
	server_name imooc.com www.imooc.com;
	access_log /usr/local/nginx/logs/access.log combined;
	index index.html index.htm index.jsp index.php;

	location / {
		proxy_pass http:www.imooc.com;
		add_header Access-Control-Allow-Origin *;
	}
}

重启nginx
./nginx -s reload

redis cookie Jackson filter 单点登录

tomcat和session:

对Tomcat而言，Session是一块在服务器开辟的内存空间，其存储结构为ConcurrentHashMap；

Http协议是一种无状态协议，即每次服务端接收到客户端的请求时，都是一个全新的请求，服务器并不知道客户端的历史请求记录；

Session的主要目的就是为了弥补Http的无状态特性。简单的说，就是服务器可以利用session存储客户端在同一个会话期间的一些操作记录；

1、服务器如何判断客户端发送过来的请求是属于同一个会话？

答：用Session id区分，Session id相同的即认为是同一个会话，在Tomcat中Session id用JSESSIONID表示；

2、服务器、客户端如何获取Session id？Session id在其之间是如何传输的呢？

答：服务器第一次接收到请求时，开辟了一块Session空间（创建了Session对象），同时生成一个Session id，并通过响应头的Set-Cookie：“JSESSIONID=XXXXXXX”命令，向客户端发送要求设置cookie的响应；

客户端收到响应后，在本机客户端设置了一个JSESSIONID=XXXXXXX的cookie信息，该cookie的过期时间为浏览器会话结束；

接下来客户端每次向同一个网站发送请求时，请求头都会带上该cookie信息（包含Session id）；

然后，服务器通过读取请求头中的Cookie信息，获取名称为JSESSIONID的值，得到此次请求的Session id；

ps：服务器只会在客户端第一次请求响应的时候，在响应头上添加Set-Cookie：“JSESSIONID=XXXXXXX”信息，接下来在同一个会话的第二第三次响应头里，是不会添加Set-Cookie：“JSESSIONID=XXXXXXX”信息的；

而客户端是会在每次请求头的cookie中带上JSESSIONID信息；

tomcat中的session是如何实现的

Tomcat中一个会话对应一个session，其实现类是StandardSession，查看源码，可以找到一个attributes成员属性，即存储session的数据结构，为ConcurrentHashMap，支持高并发的HashMap实现；
	protected Map<String, Object> attributes = new ConcurrentHashMap<String, Object>();

那么，tomcat中多个会话对应的session是由谁来维护的呢？ManagerBase类，查看其代码，可以发现其有一个sessions成员属性，存储着各个会话的session信息
	protected Map<String, Session> sessions = new ConcurrentHashMap<String, Session>();

客户端每次的请求，tomcat都会在HashMap中查找对应的key为JSESSIONID的Session对象是否存在

先看doGetSession方法中的如下代码，这个一般是第一次访问的情况，即创建session对象，session的创建是调用了ManagerBase的createSession方法来实现的; 另外，注意response.addSessionCookieInternal方法，该方法的功能就是上面提到的往响应头写入“Set-Cookie”信息；最后，还要调用session.access方法记录下该session的最后访问时间，因为session是可以设置过期时间的；
	session = manager.createSession(sessionId);

        // Creating a new session cookie based on that session
        if ((session != null) && (getContext() != null) && getContext().getServletContext(). getEffectiveSessionTrackingModes().contains(SessionTrackingMode.COOKIE)) {
            	Cookie cookie = ApplicationSessionCookieConfig.createSessionCookie(context, session.getIdInternal(), isSecure());
            	response.addSessionCookieInternal(cookie);
        }

        if (session == null) {
            return null;
        }

        session.access();
        return session;

再看doGetSession方法中的如下代码，这个一般是第二次以后访问的情况，通过ManagerBase的findSession方法查找session，其实就是利用map的key从ConcurrentHashMap中拿取对应的value，这里的key即requestedSessionId，也即JSESSIONID，同时还要调用session.access方法，记录下该session的最后访问时间；

        if (requestedSessionId != null) {
		try {
		    	session = manager.findSession(requestedSessionId);
		} catch (IOException e) {
		    	session = null;
		}
		if ((session != null) && !session.isValid()) {
		    	session = null;
		}
		if (session != null) {
		   	session.access();
		    	return (session);
		}
        }

建立会话之后, 后续的request中的sessionid(请求头), cookie中的sessionid(在浏览器开发者工具中找到的cookie)和服务器端session.getId()拿到的是想同的sessionid.

tomcat重启之后, session就会改变

单点登录 -- 就是把存在session中的用户信息改成存在redis中            
	RedisShardedPoolUtil.setEx(session.getId(), JsonUtil.obj2String(response.getData()),Const.RedisCacheExtime.REDIS_SESSION_EXTIME);

当我们把session.setAttribute("current_user", user); 修改为用redis存储用户信息之后, (key是Jsessionid): 

tomcat启动之后, request中的Jsessionid会改变, 也就是HttpSession httpSession作为参数后, httpSession.getSession()在tomcat重启之后, 会改变.

所以, 如果我们把Jsessionid当做key存在redis中, 如果tomcat重启, 则无法通过它获得用户的信息, 更重要的是, 当有两台tomcat时, 另外一台tomcat也无法获取用户的信息.

我们要在服务端, 向客户端写一个cookie, 是登录时的jsessionid.

在git拉取代码时, 用git checkout src/main/webapp/index.jsp, 可以不git pull 这个文件, 避免和本来项目中的index.jsp发生冲突.

cookie的setPath, 看包含关系来判断, 不同的path可以共享哪个cookie

git checkout . #本地所有修改的。没有的提交的，都返回到原来的状态
git stash #把所有没有提交的修改暂存到stash里面。可用git stash pop回复。
git reset --hard HASH #返回到某个节点，不保留修改。
git reset --soft HASH #返回到某个节点。保留修改

用nginx负载均衡两台tomcat, 每次轮询到相同的tomcat时, 其jsessionid都不相同.

当我们调用login.do时, 会把当前的jsessionid(也可以是uuid字符串)写入的cookie中(首先给一个名字, 比如token, 其次要设置cookie的path, 比如是.happymmall.com, 再设置有效期). 接着, 就要把这个当前的jsessionid(也可以是uuid字符串)作为key, user作为value写入redis中.

CookieUtil.writeLoginToken(httpServletResponse,session.getId());
RedisShardedPoolUtil.setEx(session.getId(), JsonUtil.obj2String(response.getData()),Const.RedisCacheExtime.REDIS_SESSION_EXTIME);

String loginToken = CookieUtil.readLoginToken(httpServletRequest);
String userJsonStr = RedisShardedPoolUtil.get(loginToken);

==> 在我们对网站的任何操作之后, 只要在登录环境下, 都应该把token的有效期重置为30min

@Override
public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
	//1. 强转
	HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;
	//2. 拿到loginToken
	String loginToken = CookieUtil.readLoginToken(httpServletRequest);

	//3. 更新session过期时间
	if (StringUtils.isNotEmpty(loginToken)) {
		//判断logintoken是否为空或者""；
		//如果不为空的话，符合条件，继续拿user信息

		String userJsonStr = RedisShardedPoolUtil.get(loginToken);
		User user = JsonUtil.string2Obj(userJsonStr, User.class);
		if (user != null) {
			//如果user不为空，则重置session的时间，即调用expire命令
			RedisShardedPoolUtil.expire(loginToken, Const.RedisCacheExtime.REDIS_SESSION_EXTIME);
		}
	}

	filterChain.doFilter(servletRequest, servletResponse);
}

在web.xml中加上过滤器
<!-- 二期新增重置session时间的filter -->
<filter>
	<filter-name>sessionExpireFilter</filter-name>
	<filter-class>com.mmall.controller.common.SessionExpireFilter</filter-class>
</filter>
<filter-mapping>
	<filter-name>sessionExpireFilter</filter-name>
	<url-pattern>*.do</url-pattern>
</filter-mapping>

String loginToken = CookieUtil.readLoginToken(httpServletRequest);
if(StringUtils.isEmpty(loginToken)){
    	return ServerResponse.createByErrorMessage("用户未登录,无法获取当前用户的信息");
}
String userJsonStr = RedisShardedPoolUtil.get(loginToken);
User user = JsonUtil.string2Obj(userJsonStr,User.class);


redis一致性算法

将数据和用来缓存的机器进行相同的hash操作, 然后放在同一个hash环形空间中.
当移除或者添加用来缓存的机器时, 数据的重新分配很少

会有ip倾斜性, 也就是用来缓存的机器都集中在环形空间的一侧, 这样导致很多数据会集中在一个缓存机器上

解决: 虚拟节点

增加很多个虚拟节点, 对每个虚拟节点进行hash操作, 来映射到真实的节点上(用虚拟节点对真实节点进行放大)

只要启动两个redis, 把端口改为6379, 6380

spring session的集成

不支持分片集群的redis

引入pom
配置JedisConnectionfactory
配置DelegatingFilterProxy
配置RedisHttpSessionConfiguration
配置DefaultCookieSerializer
配置JedisPoolConfig

<filter>
	<filter-name>springSessionRepositoryFilter</filter-name>
	<filter-class>org.springframework.web.filter.DelegatingFilterProxy</filter-class>
</filter>
<filter-mapping>
	<filter-name>springSessionRepositoryFilter</filter-name>
	<url-pattern>*.do</url-pattern>
</filter-mapping>

引入框架之后, 原先在Controller方法的参数中写的HttpSession对象会被spring session框架包装

注意: 要对User类实现序列化接口

监听redis的日志命令 monitor
可以查看spring session框架都做了什么

全局异常处理

方法一:
@Component
@Slf4j
public class ExceptionResolver implements HandlerExceptionResolver {

    /**
     * 解决异常的方法
     *
     * @param httpServletRequest
     * @param httpServletResponse
     * @param o
     * @param e
     * @return
     */
    @Override
    public ModelAndView resolveException(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) {

        log.error("{} Exception", httpServletRequest.getRequestURI(), e);
        //因为是前后端分离的, 所以要转化成JsonView
        ModelAndView modelAndView = new ModelAndView(new MappingJacksonJsonView());

        //当使用是jackson2.x的时候使用MappingJackson2JsonView，课程中使用的是1.9。
        modelAndView.addObject("status", ResponseCode.ERROR.getCode());
        modelAndView.addObject("msg", "接口异常,详情请查看服务端日志的异常信息");
        modelAndView.addObject("data", e.toString());

        return modelAndView;
    }
}

方法二
@ControllerAdvice
public class SellExceptionHandler {

    @Autowired
    private ProjectUrlConfig projectUrlConfig;

    //拦截登录异常(加注解捕获）
    //http://sell.natapp4.cc/sell/wechat/qrAuthorize?returnUrl=http://sell.natapp4.cc/sell/seller/login
    
    @ExceptionHandler(value = SellerAuthorizeException.class)
    public ModelAndView handlerAuthorizeException() {
        //直接跳转到登录页面
        return new ModelAndView("redirect:"
        .concat(projectUrlConfig.getWechatOpenAuthorize())
        .concat("/sell/wechat/qrAuthorize")
        .concat("?returnUrl=")
        .concat(projectUrlConfig.getSell())
        .concat("/sell/seller/login"));
    }

    @ExceptionHandler(value = SellException.class)
    @ResponseBody
    public ResultVO handlerSellerException(SellException e) {
        return ResultVOUtil.error(e.getCode(), e.getMessage());
    }

    @ExceptionHandler(value = ResponseBankException.class)
    @ResponseStatus(HttpStatus.FORBIDDEN)
    public void handlerResponseBankException() {
    }
}

不是所有的方法都适合用restful接口

因为要把所有的controller方法的参数都写在url中, 这时候如果参数不全部传, 会造成表意不明, 无法映射到某一个确定的方法

select ... for update 是悲观锁: 使用InnoDB引擎
在明确主键, 而且有结果集的情况下, 才会产生行锁, 否则就是表锁

<select id="selectOrderStatusByCreateTime" resultMap="BaseResultMap" parameterType="map">
    SELECT
    <include refid="Base_Column_List"/>
    from mmall_order
    where status = #{status}
    <![CDATA[
    and create_time <= #{date}
    ]]>
    order by create_time desc
  </select>

定时关单时, 需要用到redis的分布式锁. 因为只希望有一个tomcat来执行关单的逻辑. 

setnx: 原子性的, A进程如果之前已经设置成功了一个key, 则B进程就无法设置了, 就会返回0
getset
expire
del

setnx(lockKey, currentTime+timeout)

分布式锁版本一:

当来到****处, tomcat1获取到锁之后, 设置到redis中, 此时关闭系统, 则还没来得及走到closeOrder方法的设置key有效期的那里, 导致这个key永久有效, 从而发生了死锁

解决方法:
如果我们使用tomcat的shutdown命令关闭它, tomcat会执行加了注解的方法
@PreDestroy //shutdown之前要执行的方法
public void delLock(){
    	RedisShardedPoolUtil.del(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
}
从而可以删除key, 避免死锁

但如果直接kill进程, 则无法解决死锁

public void closeOrderTaskV2() {
        log.info("关闭订单定时任务启动");
        long lockTimeout = Long.parseLong(PropertiesUtil.getProperty("lock.timeout","5000"));

        Long setnxResult = RedisShardedPoolUtil.setnx(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK, String.valueOf(System.currentTimeMillis() + lockTimeout)); // ****

        if(setnxResult != null && setnxResult.intValue() == 1){
		//如果返回值是1，代表设置成功，获取锁
		//问题1: 这个锁没有释放, 没有有效期, 以后别的进程就无法获得锁
		closeOrder(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
        }else{
            	log.info("没有获得分布式锁:{}", Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
        }

        log.info("关闭订单定时任务结束");
}

private void closeOrder(String lockName){
        RedisShardedPoolUtil.expire(lockName,5);//有效期50秒，防止死锁
        log.info("获取{},ThreadName:{}",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,Thread.currentThread().getName());

        int hour = Integer.parseInt(PropertiesUtil.getProperty("close.order.task.time.hour","2"));
        iOrderService.closeOrder(hour);
        //关闭订单后, 即使没到过期时间, 也要及时释放锁, 也就是删除锁
        RedisShardedPoolUtil.del(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);

        log.info("释放{},ThreadName:{}",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,Thread.currentThread().getName());
        log.info("===============================");
}

版本二

@Scheduled(cron="0 */1 * * * ?")
public void closeOrderTaskV3() {

	log.info("关闭订单定时任务启动");
	long lockTimeout = Long.parseLong(PropertiesUtil.getProperty("lock.timeout","5000"));
	Long setnxResult = RedisShardedPoolUtil.setnx(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,String.valueOf(System.currentTimeMillis()+lockTimeout));
	
	if(setnxResult != null && setnxResult.intValue() == 1){
	    	closeOrder(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
	} else {
		//未获取到锁(这里有可能发生死锁, 所以下面代码的目的是看是不是死锁，继续判断时间戳，看是否可以重置并获取到锁
		//1. 先拿到存在redis中的锁的value
		String lockValueStr = RedisShardedPoolUtil.get(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
		//2. 如果当前时间已经大于超时时间, 则这个锁超时了, 本进程有权力获得锁
		if(lockValueStr != null && System.currentTimeMillis() > Long.parseLong(lockValueStr)){
			//2.1 有权力获得锁, 意味着可以重新设置锁, 在重新设置锁的时候, 还要把原来的锁的value值拿到
			//2.2 原来锁的value值, 不一定是在步骤1拿到的那个value, 因为是集群环境, 多个tomcat执行定时任务, 所以可能值已经被别的进程改变. 所以必须获得最新的值
			//2.3 因为我要获取锁, 所以需要把锁的value重置为现在的时间
			String getSetResult = RedisShardedPoolUtil.getSet(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK,String.valueOf(System.currentTimeMillis()+lockTimeout));

			//3.1 如果getset的结果是空, 则说明没有第三个进程设置锁, 则新进程可以获取锁
			//3.2 如果getset的结果, 也就是锁的最新value和老value一致, 那么这段时间没有第三个进程获取到了锁, 所以本进程可以获得锁, 解开这个死锁, 所以可以执行关单的任务
			if(getSetResult == null || (getSetResult != null && StringUtils.equals(lockValueStr, getSetResult))){
			    	//真正获取到锁
			    	closeOrder(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
			} else {
			    	log.info("没有获取到分布式锁:{}",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
			}
		} else {
		        	log.info("没有获取到分布式锁:{}",Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
		}
	}
	log.info("关闭订单定时任务结束");
}

版本三 redisson

 <dependency>
	<groupId>org.redisson</groupId>
	<artifactId>redisson</artifactId>
	<version>2.9.0</version>
</dependency>
<dependency>
	<groupId>com.fasterxml.jackson.dataformat</groupId>
	<artifactId>jackson-dataformat-avro</artifactId>
	<version>2.9.0</version>
</dependency>

redisson初始化

@Component
@Slf4j
public class RedissonManager {
	private Config config = new Config();
	private Redisson redisson = null;
	public Redisson getRedisson() {
	    return redisson;
	}

	private static String redis1Ip = PropertiesUtil.getProperty("redis1.ip");
	private static Integer redis1Port = Integer.parseInt(PropertiesUtil.getProperty("redis1.port"));

	@PostConstruct
	private void init(){
		try {
			config.useSingleServer().setAddress(new StringBuilder().append(redis1Ip).append(":").append(redis1Port).toString());
			redisson = (Redisson) Redisson.create(config);
			log.info("初始化Redisson结束");
		} catch (Exception e) {
			log.error("redisson init error",e);
		}
	}
}

@Scheduled(cron="0 */1 * * * ?")
public void closeOrderTaskV4() {
	//最后一个参数是锁的名字
	RLock lock = redissonManager.getRedisson().getLock(Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK);
	boolean getLock = false;
	try {
		//tryLock尝试获取锁, 并把返回值传给getLock
		//注意: 解决一个坑, 就是tryLock的时间很短, 设置为0
		//如果第一个参数是1s, 因为业务逻辑执行很快, 0.5s就执行结束了, 释放锁了, 而另一个进程还在tryLock0.5s, 它也可以获取到锁, 所以, 分布式锁失效了, 解决方案就是设置tryLock的等待时间为0
		//第二个参数是释放锁的时间50s
		if (getLock = lock.tryLock(0, 50, TimeUnit.SECONDS)) {
			//获取到了锁, 尝试成功
			log.info("Redisson获取到分布式锁:{},ThreadName:{}", Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK, Thread.currentThread().getName());
			int hour = Integer.parseInt(PropertiesUtil.getProperty("close.order.task.time.hour", "2"));
		} else {
			log.info("Redisson没有获取到分布式锁:{},ThreadName:{}", Const.REDIS_LOCK.CLOSE_ORDER_TASK_LOCK, Thread.currentThread().getName());
		}
	} catch (InterruptedException e) {
		log.error("Redisson分布式锁获取异常", e);
	} finally {
		if (!getLock) {
		    	return;
		}
		lock.unlock();
		log.info("Redisson分布式锁释放锁");
	}
}

redis主从同步

在6380里: 
slaveof 127.0.0.1 6379
只能读, 不能写

git remote rm origin
git remote add origin https://github.com/hecun1993/mmall_v2.git