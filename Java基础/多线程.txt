ThreadPoolExecutor: 可以非常方便的创建线程池对象。

	1. newCachedThreadPool()方法创建的是无界线程池，可以进行线程自动回收，此类线程池中存放线程个数理论值为Integer.MAX_VALUE最大值。
		ExecutorService executorService = Executors.newCachedThreadPool();
		for (int i = 0; i < 5; i++) {
			executorService.execute(run.new MyRunnable(" "+(i+1)));
		}

	2. 使用newCachedThreadPool(ThreadFactory)定制线程工厂, 构造函数ThreadFactory是实现定制Thread的作用
		MyThreadFactory factory = run.new MyThreadFactory();
		ExecutorService executorService = Executors.newCachedThreadPool(factory);
		executorService.execute(new Runnable() {
			@Override
			public void run() {
				System.out.println("当前线程的自定义名称为："+ Thread.currentThread().getName());
			}
		}); 

		public class MyThreadFactory implements ThreadFactory{
			@Override
			public Thread newThread(Runnable r) {
				Thread thread = new Thread(r);
				thread.setName("自定义名称："+new Date());
				return thread;
			}
		}
	
	3. 使用newFixedThreadPool(int n) 方法创建有界线程池, 此方法创建的是有界线程池，也就是池中的线程的个数可以指定最大值。
		ExecutorService executorService = Executors.newFixedThreadPool(3);
        for (int i = 0; i < 5; i++) {
            executorService.execute(run.new MyRunnable(" "+(i+1)));
        }

		ExecutorService executorService = Executors.newSingleThreadExecutor();
        for (int i = 0; i < 5; i++) {
            executorService.execute(run.new MyRunnable(" "+(i+1)));
        }

	ThreadPoolExecutor extends AbstractExecutorService implements ExecutorService extends Executor

	Executor接口很简单，只有一个execute方法。
	ExecutorService是Executor的子接口，增加了一些常用的对线程的控制方法，之后使用线程池主要也是使用这些方法。比如submit, isShutdown等.

	ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue<Runnable> workQueue) 构造方法, 
		corePoolSize
			核心线程数，默认情况下核心线程会一直存活，即使处于闲置状态也不会受存keepAliveTime限制。除非将allowCoreThreadTimeOut设置为true。
		maximumPoolSize
			线程池所能容纳的最大线程数。超过这个数的线程将被阻塞。当任务队列为没有设置大小的LinkedBlockingDeque时，这个值无效。	
		keepAliveTime
			非核心线程的闲置超时时间，超过这个时间就会被回收。
		unit
			指定keepAliveTime的单位，如TimeUnit.SECONDS。当将allowCoreThreadTimeOut设置为true时对corePoolSize生效。
		workQueue
			线程池中的任务队列.
			常用的有三种队列，SynchronousQueue,LinkedBlockingDeque,ArrayBlockingQueue。
		threadFactory
			线程工厂，提供创建新线程的功能。ThreadFactory是一个接口，只有一个方法
		RejectedExecutionHandler
			当线程池中的资源已经全部使用，添加新线程被拒绝时，会调用RejectedExecutionHandler的rejectedExecution方法

	如果线程数量 <= 核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。
	如果线程数量 > 核心线程数，但 <= 最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。
	如果线程数量 > 核心线程数，但 <= 最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。
	如果线程数量 > 核心线程数，并且 > 最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，线程池的最大线程数设置是无效的，他的线程数最多不会超过核心线程数。
	如果线程数量 > 核心线程数，并且 > 最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。



AQS: AbstractQueuedSynchronized 
	
	类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch

	它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）
		getState()
		setState()
		compareAndSetState()

	AQS定义两种资源共享方式：
		Exclusive（独占，只有一个线程能执行，如ReentrantLock）
		Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）
	
	一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。

		①isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
		②tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
		③tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
		④tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
		⑤tryReleaseShared(int)：共享方式。尝试释放资源，成功则返回true，失败则返回false。

	不同的自定义同步器争用共享资源的方式也不同。
	自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。

	可重入锁 / 公平锁 / 非公平锁:
		以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败, 然后进入等待队列中，直到A线程unlock(), state--, 直到state=0（即释放锁），其它线程才有机会获取该锁。
		当A线程拥有锁的时候，status>0. B线程尝试获取锁的时候会对这个status有一个CAS(0,1)(set state = 1)的操作，尝试几次失败后就挂起线程，进入一个等待队列。
		如果A线程恰好释放，--status==0, A线程会去唤醒等待队列中第一个线程，即刚刚进入等待队列的B线程，B线程被唤醒之后回去检查这个status的值，尝试CAS(0,1),而如果这时恰好C线程也尝试去争抢这把锁
			非公平锁实现：
				C直接尝试对这个status CAS(0,1)操作，并成功改变了status的值，B线程获取锁失败，再次挂起，这就是非公平锁，B在C之前尝试获取锁，而最终是C抢到了锁。
			公平锁：
				C发现有线程在等待队列，直接将自己进入等待队列并挂起,B获取锁
			可重入锁:
				释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。

		再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare-and-Swap 比较和交换)减1。等到所有子线程都执行完后(即state=0)，会unpark()调用主线程，然后主调用线程就会从await()函数返回，继续剩余动作。

		调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；
		acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回
	


有t1，t2先后两个线程，都需要执行如下代码：
	synchronized(Obj.class) {
		Obj.wait(); 
	}
	t1先进，最后在Obj.wait()下卡住，这时, t1线程是waitting状态.
	t2后进，在第一行就卡住了，这时, t2线程为blocked状态。
	jvm知道如何结束blocked状态, 不需要别的线程唤醒t2(只要t1释放锁, 就可以解除blocked状态)
	但waiting状态的结束, 不由jvm控制, 必须由别的线程调用notify()方法之后, 才能结束.
	从linux内核来看，t1, t2线程都是等待状态，没区别，区别只在于jvm的管理需要

	synchronized放在普通方法上, 内置锁(java中任何对象都可以作为锁)就是当前类的实例
	synchronized放在静态方法上, 内置锁是当前类的Class对象(全局只有一份)
	synchronized修饰代码块的时候, 锁对象可以任意指定.
	static的方法属于类方法，它属于这个Class（注意：这里的Class不是指Class的某个具体对象），那么static获取到的锁，是属于类的锁。而非static方法获取到的锁，是属于当前对象的锁。所以，他们之间不会产生互斥。

内置锁 -- 与synchronized有关的概念:
	内置锁获得锁和释放锁是隐式的
	每个java对象都可以用做一个实现同步的锁，这些锁就是内置锁。线程进入同步代码块或同步方法时会自动获得该锁，在退出同步代码块或同步方法时或代码块中抛出异常退出时会释放该锁。获得内置锁的唯一途径就是进入这个锁的保护的同步代码块或方法。
	内置锁是一个互斥锁，这意味着最多只有一个线程能够获得该锁，当线程A尝试去获得线程B持有的内置锁时，线程A必须等待或者阻塞，直到线程B释放这个锁，如果B线程不释放这个锁，那么A线程将永远等待下去。

与Synchronized配套使用的通信方法通常有wait(),notify()
	wait()方法会立即释放当前锁，并进入等待状态，等待到相应的notify并重新获得锁过后才能继续执行；
	notify()不会立刻立刻释放锁，必须要等notify()所在线程执行完synchronized块中的所有代码才会释放。在线程调用notify方法时，会随机选择相应对象的等待队列的一个线程将其唤醒，而不是按照FIFO的方式，如果有强烈的公平性要求，比如FIFO就无法满足

Synchronized在JDK1.5及之前性能（主要指吞吐率）比较差，扩展性也不如ReentrantLock。但是JDK1.6以后，修改了管理内置锁的算法，使得Synchronized和标准的ReentrantLock性能差别不大。

原子类: AtomicInteger
	class MyThread implements Runnable {
	//    static  int i = 0;
		public static AtomicInteger ai = new AtomicInteger(0);
		
		public void run() {
			for (int m = 0; m < 1000000; m++) {
				ai.getAndIncrement();
			}
		}
	};
	
	public class TestAtomicInteger {
		public static void main(String[] args) throws InterruptedException {
			MyThread mt = new MyThread();
	
			Thread t1 = new Thread(mt);
			Thread t2 = new Thread(mt);
			t1.start();
			t2.start();
			Thread.sleep(500);
			System.out.println(MyThread.ai.get());
		}
	}

CAS:
	锁是一种悲观策略，它总是假定每一次的临界区操作会发生冲突，因此每次操作都小心翼翼。当多线程访问临界区资源时，宁愿牺牲性能也要让线程等待。
	无锁是乐观的策略，它假定对临界区的访问时没有冲突的，既然没有冲突，那就不用等待了。无锁基于比较交换技术（CAS：compare and swap）实现。
	相对于锁，CAS会使程序更为复杂，但由于其是非阻塞的，它对死锁天生免疫。基于CAS的无锁方式完全没有锁竞争带来的系统开销，也不存在线程间频繁调度带来的开销，它性能更为优越。

	具体实现:
		CAS(V,E,N);
		其中，V表示要更新的变量，E表示预期值，N表示新值。仅当V变量值等于E时，才将V值设为N；如果V值与E不相等，说明已经有其它线程在该过程中更新了V的值，那此时当前线程什么都不做。
	
		1、当多个线程同时使用CAS操作一个变量时，只会有一个线程胜出，并成功更新值，其它线程均会失败。失败的线程不会挂起，仅是被告知失败，并且运行再次尝试，当然，也运行失败的线程放弃操作。
		2、在硬件层面上，大部分处理器都已经支持原子化的CAS指令
	
	synchronized是阻塞同步的方式
	常见的非阻塞同步有：
 	    a.volatile 变量：轻量级的线程同步，不会引起线程调度，提供可见性，但是不提供原子性
      	b.CAS 原子指令：轻量级线程同步，不会引起线程调度，提供可见性和原子性。

	常用的非阻塞算法的容器包括：ConcurrentLinkedQueue，SynchronousQueue，Exchanger 和 ConcurrentSkipListMap，包括J.U.C里面的整数原子类AtomicInteger等

		public static AtomicInteger race = new AtomicInteger();  
	
		public static void main(String[] args) {  
			// 这是自增方法，我们看看如何实现了 类似 i++ 的功能。  
			race.incrementAndGet();  
		}  

		//----------------------------------------------
	  	
		public final int incrementAndGet() {  
			for (;;) {  
				// 先获得当前值  
				int current = get();  
				// 然后计算增加后的值，也就是我们的预期值  
				int next = current + 1;  
				// 然后预期值和 当前值进行比较（看下面）  
				if (compareAndSet(current, next))  
					return next;  
			}  
		}  
  
		public final int get() {  
			return value;  
		}  
		
		// 这里是通过当前类在内存中的值,valueOffset,  
		// 期望的值expect，需要更新的值update  
		// 进行比较，如果valueOffset 表示的值，和当前except 值等，那么我们执行修改，  
		// 否则表示已经被其他线程更改了，不执行，循环继续。  
		public final boolean compareAndSet(int expect, int update) {  
			return unsafe.compareAndSwapInt(this, valueOffset, expect, update);  
		}

		关于valueOffset 的值的取得，是通过Unsafe.getUnsafe()获得实例的 objectFieldOffset 方法获得的，是native 方法，JAVA 仅仅允许启动类加载(Bootstrap ClassLoader) 的类才能访问，反射也可以的，这是它内部代码： 

		private static final Unsafe unsafe = Unsafe.getUnsafe();  
		private static final long valueOffset;  
		
		static {  
			try {  
				// 这里可以定位当前类字段value在内存中的值  
				valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));  
			} catch (Exception ex) { 
				throw new Error(ex); 
			}  
		}  

		CAS的ABA问题
		从上面CAS 的原理分析，假设变量i 的原始值是i=5,A 线程通过get() 方法，获取值等于V，然后这时候B线程用同样的方式获得V，然后改成了6,(中途可能被其他使用)，然后又改回成5.这时候 A线程去判断的时候，发现内存值还是5，说明没有改变，就执行更新。但是我们发现 在中途其实已经改变过了，又改变回来了而已，这就是ABA 问题。
		
		// setup to use Unsafe.compareAndSwapInt for updates  
		private static final Unsafe unsafe = Unsafe.getUnsafe();  
		private static final long valueOffset;  
		private volatile int value;  
		这里， unsafe是java提供的获得对对象内存地址访问的类，注释已经清楚的写出了，它的作用就是在更新操作时提供“比较并替换”的作用。实际上就是AtomicInteger中的一个工具。

		valueOffset是用来记录value本身在内存的编译地址的，这个记录，也主要是为了在更新操作在内存中找到value的位置，方便比较。

		注意：value是用来存储整数的时间变量，这里被声明为volatile，就是为了保证在更新操作时，当前线程可以拿到value最新的值（并发环境下，value可能已经被其他线程更新了）。


1. interrupt()的作用是中断本线程的执行。
	本线程中断自己是被允许的；
	其它线程调用本线程的interrupt()方法时，会通过checkAccess()检查权限。这有可能抛出SecurityException异常

2. 如果本线程是处于阻塞状态：
	调用线程的wait(), wait(long)或wait(long, int)会让它进入等待(阻塞)状态，或者调用线程的join(), join(long), join(long, int), sleep(long), sleep(long, int)也会让它进入阻塞状态。

	若线程在阻塞状态时，调用了它的interrupt()方法，那么它的“中断状态”会被清除并且会收到一个InterruptedException异常。
	例如，线程通过wait()进入阻塞状态，此时通过interrupt()中断该线程；
	调用interrupt()会立即将线程的中断标记设为“true”，但是由于线程处于阻塞状态，所以该“中断标记”会立即被清除为“false”，同时，会产生一个InterruptedException的异常。

java interrupt()方法只是设置线程的中断标记，当对处于阻塞状态的线程调用interrupt方法时，会抛出InterruptException异常，而这个异常会清除中断标记。


可重入锁，也叫做递归锁，指的是同一线程外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，不受影响。也就是在一个线程中可以多次获取同一把锁, ReentrantLock和synchronized都是可重入锁。
	一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法，而无需重新获得锁；
	最大的作用是避免死锁。在很多情况下线程需要多次进入锁内执行任务。
		比如数据库事务的实现过程中。add操作将会获取锁，若一个事务当中多次add，就应该允许该线程多次进入该临界区。

与可重入锁synchronized和Lock不同的就是自旋锁。
若有同一线程两调用lock() ，会导致第二次调用lock位置进行自旋，产生了死锁说明这个锁并不是可重入的。


1. 基本概念 
	线程和进程
		1. 进程包含很多线程; 不同进程有相互独立的逻辑内存; 多个进程不能共享内存.
		2. 线程没有自己独立的地址空间和内存,无法独立执行,只能在应用程序中执行.多个线程可以共享内存.CPU在线程中做时间片的切换
		3. 与进程相比，线程的创建和切换开销更小。使用多线程可以减少程序的响应时间。进程一直运行，直到所有的非守候线程都结束运行后才能结束。
	
	同步和异步
		1. 在访问共享数据的情况下，线程B结束对资源使用后，线程A才能使用使用这个资源。
		2. 要实现同步操作，某一个线程必须获得一个锁对象。当拥有该对象锁的线程退出临界区时，锁才会释放。（所谓的临界区，就是访问互斥资源的代码块）
		3. 异步，就是指每个线程都包含了运行时自身所需的数据或方法。

	线程间通信:
		0. 线程间通信就是依靠共享内存实现的.
		1. 指的是不同种类的线程针对同一资源的操作.(比如生产者和消费者模型)
		2. 通信主要依靠的方法为，wait / notify / notifyAll
			这些方法的调用必须通过锁对象，而锁对象是任意对象，所以这些方法必须定义在object对象中.
		3. 系统通过调用线程类的start方法来启动一个线程,但是此时,该线程处于就绪状态,而非运行状态。只是意味着这个线程可以被JVM自动调用run方法来调度执行.

	线程的生命周期：
		新建 -- 就绪 -- 运行 -- 阻塞 -- 就绪 -- 运行 -- 死亡

	线程调度模型：
		java虚拟机采用抢占式调度模型，是指优先让可运行池中优先级高的线程占用CPU，如果可运行池中的线程优先级相同，那么就随机选择一个线程，使其占用CPU。线程的调度不是跨平台的，它不仅仅取决于java虚拟机，还依赖于操作系统。

	守护线程：
		1. 作用是为其他线程的运行提供服务，比如说GC线程。
		2. 当所有非守护线程结束时，程序也就终止了，同时会杀死进程中的所有守护线程。反过来说，只要任何非守护线程还在运行，程序就不会终止。
		注意：
			Thread.setDaemon(true)这句话，必须在start方法之前设置，否则会跑出一个IllegalThreadStateException异常。因为不能把正在运行的常规线程设置为守护线程。
			守护线程应该永远不去访问固有资源，如文件、数据库，因为它会在任何时候甚至在一个操作的中间发生中断。

2. 实现多线程的三种方法
	* Demo类继承Thread类，重写run方法，实例化Demo类，调用其start方法。
		class MyThread extends Thread{
			public void run(){
				print("thread...");
			}
		}
		public class Demo{
			main{
				MyThread myThread = new MyThread();
				myThread.start();
			}
		}
	* Demo类实现Runnable接口，实现run方法，实例化Thread类，并将实例化的Demo类作为参数传入，调用其start方法
		class MyThread implements Runnable{
			public void run(){
				print("Thread...");
			}
		}
		public class Demo{
			MyThread mt = new MyThread();
			Thread myThread = new Thread(mt);
			myThread.start();
		}
	* 实现Callable接口,实现该接口的call方法(在线程池中使用的!)。
		- Demo类实现Callable接口, 实现call方法, 给返回值; 
		- 把Demo类的实例传给FutureTask的构造函数, 构造FutureTask的实例;
		- 把FutureTask的实例传给Thread类, 然后调用start方法;
		- 接收时, 用FutureTask的实例调用get方法, 得到线程的返回结果.

		class ThreadDemo implements Callable<Integer>{
			public Integer call() throws Exception{
				print("Thread...");
			}
		}
		
		public class Demo{
			public static void main(String[] args) {
				ThreadDemo td = new ThreadDemo();
				// Callable方式，需要FutureTask, 它是Future接口的实现类，用于接收运算结果。
				FutureTask<Integer> result = new FutureTask(td);
				new Thread(result).start();
				try{
					Integer sum = result.get();
					print(sum);
				} catch (Exception e){
					e.printStackTrace();
				}
			}
		}

3. 线程池:
	* 程序启动一个新线程成本是比较高的，因为它涉及到要与操作系统进行交互。
		而使用线程池可以很好的提高性能，尤其是当程序中要创建大量生存期很短的线程时，更应该考虑使用线程池。
	* 在JDK5之前，我们必须手动实现自己的线程池，从JDK5开始，Java内置支持线程池
		要自定义一个线程池，首先要有存固定的线程数目的阻塞队列，还要有个存放任务的阻塞队列。
	  	如果任务放入时有线程为空闲直接交付于它执行否则就放入任务队列中
	  	在内部有个线程会不断的扫描任务队列如果既有空闲任务又有空闲线程就执行。
	* 线程池里的每一个线程代码结束后，并不会死亡，而是再次回到线程池中成为空闲状态，等待下一个对象来使用。
	
	JDK5新增了一个Executors工厂类来产生线程池
	产生的线程池通过调用execute / schedule方法来，传入一个Runnable对象来开启线程。
		通过Executors提供四种线程池，分别为：
		1. newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
			线程池为无限大，当执行第二个任务时第一个任务已经完成，会复用执行第一个任务的线程，而不用每次新建线程。
		public static void main(String[] args) {
			ExecutorService cachedThreadPool = Executors.newCachedThreadPool();
			for (int i = 0; i < 10; i++) {
				final int index = i;
				try {
					Thread.sleep(index * 1000);
				} catch (InterruptedException e) {
					e.printStackTrace();
				}
				cachedThreadPool.execute(new Runnable() {
					public void run() {
			 			System.out.println(index);
					}
				});
			}
		 }

		2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
			因为线程池大小为3，每个任务输出index后sleep2秒，所以每两秒打印3个数字。
			定长线程池的大小最好根据系统资源进行设置。
			
			public static void main(String[] args) {
				ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3);
				for (int i = 0; i < 10; i++) {
					final int index = i;
					fixedThreadPool.execute(new Runnable() {
						public void run() {
							try {
								System.out.println(index);
								Thread.sleep(2000);
							} catch (InterruptedException e) {
								e.printStackTrace();
							}
						}
					});
				}
			}

		3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
			public static void main(String[] args) {
				ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);
				scheduledThreadPool.schedule(new Runnable() {
					public void run() {
						System.out.println("delay 3 seconds");
					}
				}, 3, TimeUnit.SECONDS);
			}
			表示延迟3秒执行。

			public static void main(String[] args) {
	  			ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5);
	  			scheduledThreadPool.scheduleAtFixedRate(new Runnable() {
	   				public void run() {
	   					System.out.println("delay 1 seconds, and excute every 3 seconds");
	   				}
	  			}, 1, 3, TimeUnit.SECONDS);
	 		}
	 		表示延迟1秒后每3秒执行一次。

		4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

			public static void main(String[] args) {
		  		ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor();
		  		for (int i = 0; i < 10; i++) {
		   			final int index = i;
		   			singleThreadExecutor.execute(new Runnable() {
		    			public void run() {
		     				try {
						    	System.out.println(index);
						    	Thread.sleep(2000);
		     				} catch (InterruptedException e) {
		      					e.printStackTrace();
		     				}
		    			}
		   			});
		  		}
		 	}
		 	结果依次输出，相当于顺序执行各个任务。

	这些方法的返回值是ExecutorService对象，该对象表示一个线程池，可以执行Runnable对象或者Callable对象代表的线程。它提供了如下方法：
		Future submit(Runnable task)
		Future submit(Callable task)

	1. Excutor是顶层接口，只有一个excute方法，参数为Runnable类
	2. ExcutorService是接口，提供了submit方法，参数可以是Callable<T>，也可以是Runnable，有返回值，为Future。（将来的某个时间，线程执行完毕后的返回值）
	3. Excutors是线程池的工具类，用来创建各种线程。fixed，cached，single，scheduled，workstealing(如果本队列执行完毕，会从其他队列中拿任务执行)，forkjoin(先将任务拆分后计算结果，然后再合并)。其创建后的类型就是ExcutoreService，可以执行excute方法
		代码: 
			new Thread(new FutureTask(new Callable<Integer> {})).start();
			FutureTask<Integer> f1 = new FutureTask(new Callable<Integer> {});
			f1.get(); 这个get方法回阻塞，等待线程执行完后，有结果。
			========
			Future<Integer> f1 = Excutors.newFixedThreadPool(3).submit(new Callable<Integer> {});
			f1.get(); 这个get方法回阻塞，等待线程执行完后，有结果。

	使用线程池的好处：(减少创建销毁线程的开销; 控制线程数量, 保持系统的稳定性)
		* 新建线程的开销。线程虽然比进程要轻量许多，但对于JVM来说，新建一个线程的代价还是挺大的，决不同于新建一个对象
		* 资源消耗量。没有一个池来限制线程的数量，会导致线程的数量直接取决于应用的并发量，这样有潜在的线程数据巨大的可能，那么资源消耗量将是巨大的
		* 稳定性。当线程数量超过系统资源所能承受的程度，稳定性就会成问题

4. 五种线程同步的方式
	多线程中的非同步问题主要出现在对域的读写上，如果让域自身避免这个问题，则就不需要修改操作该域的方法。
		==> 用final域，有锁保护的域和volatile域可以避免非同步的问题。

	* synchronized是和if、else、for、while一样的关键字，ReentrantLock是类
	
	* 有synchronized关键字修饰的方法。
		java的每个对象都有内置锁，该内置锁会保护整个方法
			public synchronized void save(int money) {
			    account += money;
			}

	* 同步代码块
		有synchronized关键字修饰的语句块。 
		通常没有必要同步整个方法，使用synchronized代码块同步关键代码即可。
			synchronized (this) {
            	account += money;
            }

    * 使用特殊域变量(volatile)实现线程同步
    	* volatile关键字为域变量的访问提供了一种免锁机制， 
	    * 使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新， 
	    * 因此每次使用该域就要重新到内存中获取值，而不是使用寄存器中的值 
	    * volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 
	    	private volatile int account = 100;

	* ReentrantLock
		虽然我们可以理解同步代码块和同步方法的锁对象问题，但是我们并没有直接看到在哪里加上了锁，在哪里释放了锁，为了更清晰的表达如何加锁和释放锁，JDK5以后提供了一个新的锁对象Lock

		ReentrantLock() : 创建一个ReentrantLock实例 
        lock() : 获得锁 
        unlock() : 释放锁 
       		private int account = 100;
       		private Lock lock = new ReentrantLock();
       		public void save(int money){
       			lock.lock();
       			try{
       				account += money;
       			} finally {
       				lock.unlock();
       			}
       		}

    * ThreadLocal:使用局部变量实现线程同步
    	在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。
		
		初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。

　　		然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。
	
		1）实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的；
		
		2）为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像longLocal和stringLocal；
		
		3）在进行get之前，必须先set，否则会报空指针异常；如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。

    	使用ThreadLocal管理变量，每一个线程都会获得该变量的副本，副本之间相互独立，每一个线程都可以随意修改副本的值，而不会对其他线程产生影响。
    		ThreadLocal() : 创建一个线程本地变量 
		    get() : 返回此线程局部变量的当前线程副本中的值 
		    initialValue() : 返回此线程局部变量的当前线程的"初始值" 
		    set(T value) : 将此线程局部变量的当前线程副本中的值设置为value

		   	private static ThreadLocal account = new ThreadLocal() {
                @Override
                protected Integer initialValue(){
                    return 100;
                }
            };
            public void save(int money){
                account.set(account.get() + money);
            }
            public int getAccount(){
                return account.get();
            }

5. 内存模型中的可见性、原子性和有序性
	可见性：
		* 指线程之间的可见性，一个线程修改的状态对另一个线程是可见的。也就是一个线程修改的结果。另一个线程马上就能看到。
			比如：用volatile修饰的变量，就会具有可见性。
		* volatile、synchronized和final修饰的属性具有可见性
	
	原子性：
		* 如果一种操作是不可分割的，比如 a=0; 就具有原子性。而a++; 实际是a = a + 1; 是可分割的，所以不是原子操作.
		* 非原子操作都会存在线程安全问题，需要我们使用同步技术，让它变成一个原子操作。
	
	有序性：
		* Java提供了volatile和synchronized两个关键字来保证线程之间操作的有序性。
		* volatile本身包含“禁止指令重排序”的语义。
		* synchronized使“一个变量在同一个时刻只允许一条线程对其进行lock操作”。此规则决定了持有同一个对象锁的两个同步块只能串行执行。

		JMM中的核心是happens-before原则:
		    - 编写的程序都要经过优化后（编译器和处理器会对我们的程序进行优化以提高运行效率）才会被运行，优化分为很多种，其中有一种优化叫做重排序，重排序需要遵守happens-before规则，不能说你想怎么重排就怎么重排.
		    - 如果A操作的结果, B操作要用到, 则不可以进行重排序.

	乐观锁与悲观锁:
		Java在JDK1.5之前都是靠synchronized关键字保证同步的，这就是一种悲观锁.

		更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。
			1. CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。
			2. CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前值。）

		对于synchronized这种阻塞算法，CAS是非阻塞算法的一种常见实现。
			以java.util.concurrent中的AtomicInteger为例
				public final int getAndIncrement() {  
			        for (;;) {  
			            int current = get();  
			            int next = current + 1;  
			            if (compareAndSet(current, next))  
			                return current;  
			        }  
	   			}  

6. volatile原理：
	* 是一种稍弱的同步机制，不允许线程内部缓存和重排序，可以确保将变量的更新操作通知到其他线程。但不能保证它具有原子性。
	* 当把变量声明为volatile后，编译器与运行时都会注意到这个变量是共享的，因此，不会将该变量上的操作与其他内存操作一起重排序。
	* 当对非volatile变量进行读写的时候，每个线程先从内存拷贝变量到CPU缓存中。这样，A线程对变量修改后同步到内存，但是B线程还是从其CPU缓存中读取旧的值。就会产生线程安全问题。而被volatile修饰的变量，每个线程读取值，都会从内存中读取。
	* 在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步机制。

7. 锁的释放问题
	什么情况下会释放锁：
		1. 执行完同步代码块
		2. 执行同步代码块的过程中，遇到异常而导致线程终止
		3. 执行同步代码块的过程中，执行了锁所属对象的wait方法，这个线程会释放锁，让其他线程可以进入synchronized数据块，进入对象的等待池。
	
	什么情况下不会释放锁：
		1. 在执行同步代码块的过程中，执行了Thread.sleep()，sleep需要传入时长。
		2. 在执行同步代码块的过程中，执行了Thread.yield()，yield不需要传入时长。
		3. notify方法，也不会立即释放锁，而是要等到synchronized方法执行完，才会真正释放锁。它只是唤醒其他wait的线程，并让它有机会获得CPU的执行权。
		
8. 方法辨析
	synchronized/lock：lock不会一直等待, 可以等一段时间, 可以知道有没有成功获取到锁. 有更多的方法.
		* lock可以不让等待的线程一直无期限的等待下去，比如只等待一定的时间或者能够响应中断。但synchronized就不行。但由于synchronized可以自动释放锁，所以不会发生死锁。
		* lock可以知道线程有没有成功获取到锁
		* 使多个读线程操作不需要上锁。

		* lock是一个接口。ReentrantLock是唯一实现Lock的类。ReentrantReadWriteLock里面提供了很多丰富的方法，不过最主要的有两个方法：readLock()和writeLock()用来获取读锁和写锁。
			* lock：获取锁，如果锁被其他线程获取，则等待。要把释放锁的unlock()放在finally中
			* tryLock：有返回值，无法获取则返回false，也就是这个方法会立即返回，拿不到锁也不会一直等待。其可以加一个时间参数，表示这个时间段内做获取锁的尝试
			* lockInterruptibly：当两个线程同时通过lock.lockInterruptibly()想获取某个锁时，假若此时线程A获取到了锁，而线程B只有等待，那么对线程B调用threadB.interrupt()方法能够中断线程B的等待过程。
			注意，当一个线程获取了锁之后，是不会被interrupt()方法中断的。

	wait/notify:
		调用wait方法的原则：
			* 当前线程必须拥有共享对象的锁，才能调用共享对象的wait方法，让当前线程阻塞。
			* 应该对在多线程间共享的那个Object来调用其wait方法。在生产者消费者问题中，这个共享的Object就是那个缓冲区队列。
			* 应该在synchronized函数或者synchronized块中调用wait方法。希望上锁的对象就应该被synchronized，即那个在多个线程间被共享的对象应该被synchronized。在生产者消费者问题中，应该被synchronized的就是那个缓冲区队列。
			* 应该永远在while循环，而不是if语句中调用wait方法。
				* 因为在多线程环境中，共享对象的状态随时可能改变。当一个在对象等待池中的线程被唤醒后，并不一定立即恢复运行，等到这个线程获得了锁及CPU才能继续运行，此时对象的状态可能已经发生了变化，所以需要再次while判断。

		wait：
			* wait是指在一个已经进入了同步锁的线程内，让自己暂停执行，并释放同步锁，让其他线程可以进入synchronized数据块，当前线程被放入对象等待池中，其他正在等待此锁的线程可以得到同步锁并运行。
			* 只有其他线程调用了notify方法，调用wait方法的一个或多个线程就会解除wait状态，重新参与竞争对象锁，程序如果可以再次得到锁，就可以继续向下运行。
			* 调用该方法后当前线程进入睡眠状态，直到以下事件发生。
				（1）其他线程调用了该对象的notify方法。
				（2）其他线程调用了该对象的notifyAll方法。
				（3）其他线程调用了interrupt中断该线程。
				（4）时间间隔到了。
				此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。
		
		notify：
			* 当调用notify()方法后，将从对象的等待池中移走一个任意的线程并放到锁标志等待池中，只有锁标志等待池中线程能够获取锁标志
			* notify/notifyAll并不真正释放锁，必须等到synchronized方法或者语法块执行完才真正释放锁。
			* notify方法只是告诉调用过wait方法的线程可以去参与获得锁的竞争了。但该线程不是马上得到锁，因为锁还在调用notify的线程那里，不一定被释放了。

		1）wait()、notify()和notifyAll()方法是本地方法，并且为final方法，无法被重写。
		2）调用notify方法只能够唤醒一个正在等待共享对象的锁的线程。
 		3）调用notifyAll方法能够唤醒所有正在等待这个对象的monitor的线程，唤醒的线程获得锁的概率是随机的，取决于cpu调度。

 	Condition:
		* Condition接口是在java 1.5中才出现的，它用来替代传统的Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify()，使用Condition的await()、signal()这种方式实现线程间协作更加安全和高效。
		* Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition()
		* 调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock()之间才可以使用Conditon中的await()对应Object的wait()； 
		* Condition中的signal()对应Object的notify()；Condition中的signalAll()对应Object的notifyAll()

 	start/run:
 		调用start方法，将会创建新的线程，并且执行在run方法里的代码。但如果直接调用run方法，不会创建新的线程也不会执行调用线程的代码。

	sleep:
		* 使当前线程暂停执行一段时间(时长可以设定)，让其他线程有机会继续执行，但它并不释放对象锁。也就是说如果有synchronized同步块，其他线程仍然不能访问共享数据。注意该方法要捕捉异常。
		* 可以使低优先级的线程得到执行机会。
			* 例如有两个线程同时执行(没有synchronized)一个线程优先级为MAX_PRIORITY，另一个为MIN_PRIORITY，如果没有Sleep()方法，只有高优先级的线程执行完毕后，低优先级的线程才能够执行；但是高优先级的线程sleep(500)后，低优先级就有机会执行了。

	yield：
		* yield与sleep类似，yield方法使当前线程让出CPU占有权，但让出的时间是不可设定的。
		* yield方法只能让同优先级的线程有执行的机会。
	 	* yield不会释放锁，只是让当前线程重新回到可执行状态。
	 		* 其执行过程是：先检测当前是否有相同优先级的线程处于可运行状态，如有，则把CPU的占有权交给该线程，否则继续运行原来的线程。所以执行yield()的线程有可能在进入到可执行状态后马上又被执行。

	sleep/wait:
		* 最大的不同是在等待时wait会释放锁，而sleep一直持有锁。wait通常被用于线程间交互，sleep通常被用于暂停执行。
		* sleep是Thread类的静态方法，wait是Object方法。
		* wait，notify和notifyAll只能在同步控制方法或者同步控制块里面使用，而sleep可以在任何地方使用。
		* sleep必须捕获异常，而wait，notify和notifyAll不需要捕获异常。

	join:
		* 在线程B中调用线程A的join方法，A线程就拿到了CPU的执行权，开始执行A线程，直到线程A执行完毕后，才会继续执行线程B。要捕捉异常。
		* join方法可以用于临时加入线程。
			* 比如有T1、T2、T3三个线程，如何怎样保证T2在T1执行完后执行，T3在T2执行完后执行？
			* 答案是使用join方法。T3先执行，在T3的run中，调用t2.join，让t2执行完成后再执行t3; 在T2的run中，调用t1.join，让t1执行完成后再让T2执行

9. 读写锁：
	如果需要实现一个高效的缓存，它允许多个用户读，但只允许一个用户写，以此来保持它的完整性，如何实现？
	
	读写锁ReadWriteLock拥有更加强大的功能，它可细分为读锁和解锁。
  	读锁可以允许多个进行读操作的线程同时进入，但不允许写进程进入；写锁只允许一个写进程进入，在这期间任何进程都不能再进入。（完全符合题目中允许多个用户读和一个用户写的条件）
  		private ReadWriteLock rwl = new ReentrantReadWriteLock();
  		private Integer data = 10;

  		//读
  		public void get() {  
	        rwl.readLock().lock();  //读锁开启，读线程均可进入  
	        try { //用try finally来防止因异常而造成的死锁  
	            System.out.println(Thread.currentThread().getName() + "is ready to read");  
	            Thread.sleep(new Random().nextInt(100));  
	            System.out.println(Thread.currentThread().getName() + "have read date" + data);  
	        } catch (InterruptedException e) {  
	            e.printStackTrace();  
	        } finally {  
	            rwl.readLock().unlock(); //读锁解锁  
	        }  
	    }  
  		
  		//写
	    public void put(Object data) {  
	        rwl.writeLock().lock();  //写锁开启，这时只有一个写线程进入  
	        try {  
	            System.out.println(Thread.currentThread().getName() + "is ready to write");  
	            Thread.sleep(new Random().nextInt(100));  
	            this.data = data;  
	            System.out.println(Thread.currentThread().getName() + "have write date" + data);  
	        } catch (InterruptedException e) {  
	            e.printStackTrace();  
	        } finally {  
	            rwl.writeLock().unlock(); //写锁解锁  
	        }  
	    } 

10. 死锁：
	指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。

	发生死锁的条件：
		1）互斥条件：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。
		2）请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。
		3）不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
		4）环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。
	
	如何处理死锁：
		1) 预防死锁。
			这是一种较简单和直观的事先预防的方法。方法是通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或者几个，来预防发生死锁。预防死锁是一种较易实现的方法，已被广泛使用。但是由于所施加的限制条件太严格，可能会导致系统资源利用率和系统吞吐量降低。
		2) 避免死锁。
			该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施去破坏产生死锁的的四个必要条件，而是在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。
		3)检测死锁。
			这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进入不安全区，此方法允许系统在运行过程中发生死锁。但可通过系统所设置的检测机构，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源，然后采取适当措施，从系统中将已发生的死锁清除掉。
		4)解除死锁。
			这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。死锁的检测和解除措施，有可能使系统获得较好的资源利用率和吞吐量，但在实现上难度也最大。

	简单描述：
		* 线程T1持有锁L1并且申请获得锁L2，线程T2持有锁L2并且申请获得锁L1，因为默认的锁申请操作都是阻塞的，所以线程T1和T2永远被阻塞了，导致死锁。
		* 实际环境中的死锁比这个复杂的多。可能会有多个线程形成了一个死锁的环路。
		* 在获得了锁L1，并且没有释放锁L1的情况下，又去申请获得锁L2，这个是产生死锁的最根本原因。另一个原因是默认的锁申请操作是阻塞的。
		* 如果我们能够避免在对象的同步方法中调用其它对象的同步方法，那么就可以避免死锁产生的可能性。

	银行家算法：避免死锁
	    它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。
	    我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。 
	为保证资金的安全,银行家规定: 
	    (1) 当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客; 
	    (2) 顾客可以分期贷款,但贷款的总数不能超过最大需求量; 
	    (3) 当银行家现有的资金不能满足顾客尚需的贷款数额时,对顾客的贷款可推迟支付,但总能使顾客在有限的时间里得到贷款; 
	    (4) 当顾客得到所需的全部资金后,一定能在有限的时间里归还所有的资金。
	资源有序分配法：预防死锁
	资源分配图化简法：检测死锁
	撤销进程法：解决死锁