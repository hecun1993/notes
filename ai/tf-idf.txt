TF-IDF（Term Frequency–Inverse Document Frequency）关键词统计方法：它用以评估一字/词对于一个文件集或一个语料库中的其中一份文件的重要程度，字/词的重要性会随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。

在一份给定的文件里，词频（term frequency，TF）指的是某一个给定的词语在该文件中出现的次数。
某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取对数得到。

假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频就是 0.03 (3/100)。一个计算文件频率 (DF) 的方法是测定有多少份文件出现过“母牛”一词，然后除以文件集里包含的文件总数。所以，如果“母牛”一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是 9.21 ( ln(10,000,000 / 1,000) )。最后的TF-IDF的分数为0.28( 0.03 * 9.21)。

因此，某个词的权重值大小与词频数不呈正比。

制作词云。

由于LDA属于概率主题模型的子类，那就先从“概率主题模型”说起：

概率主题模型（Statistical Topic Models）是一类从文本文档中提取潜在语义信息的有效方法。概率主题模型的基本原理认为文档是若干主题的混合概率分布，而每个主题又是一个关于单词的混合概率分布，可以看作是文档的一种生成模型。在概率主题的各项方法当中，潜在狄利克雷分配模型（LDA model）是最为有效的模型之一。

LDA是一种典型的无监督（也就是每段文本没有标签，我们事先不知道里面说的是啥）、基于统计学习的词袋模型，即它认为一篇文档是由一组词构成的一个集合，词与词之间没有顺序以及先后的关系。一篇文档可以包含多个主题，文档中每一个词都由其中的一个主题生成。主题模型通过分析文本中的词来发现文档中的主题、主题之间的联系方式和主题的发展，通过主题模型可以使我们组织和总结无法人工标注的海量电子文档。

类似Kmeans聚类，LDA模型的主题数也需要人工来确定，笔者在尝试了多个主题数之后，确定了最终的主题数，从下面的LDA可视化图形可以看出，主题数为6时，很多主题所涵盖的关键词出现严重的重叠，而分成10个主题后，情况得到好转。

下图“打印”出这10个主题及其下辖的20个关键词，以“权重值*词汇”的累加形式呈现，各个权重值其实是该词汇在指定主题下出现的概率大小，也可以理解为该词对该主题的“贡献”程度，比如TOP0中的“孩子”前的权重系数为0.008，表明在TOP0的话题下，“孩子”被“抽中”的概率为0.008。依次类推，各个词语w在主题T下出现的概率分布称之为词分布，这个词分布也是一个多项分布。

对于上图中的主题词列表（表示与各个潜在主题最为相关的一些词语），笔者还进行了可以点击交互的可视化展示，可以看到每个主题下的关键词在该话题下及总的文本中的占比情况，从中可以看出某个词对于该主题的重要程度如何。如下图中TOP1下的关键词“摩拜”，在该主题中出现的概率最大，重要性最高，红色条柱代表它在TOP1下的比重，而蓝色条柱的是它在整个文本（88,291篇文章）中的比重。某个词对该主题重要性最显著的情况是：蓝色条柱更短、红色条柱越长，这类词更能对主题进行区隔。