启动zk:
./zkServer start

启动kafka:
./kafka-server-start.sh -daemon /home/hadoop/app/kafka_2.11-0.9.0.0/config/server.properties
nohup ./bin/kafka-server-start.sh config/server.properties & 

创建kafka的topic:
./kafka-topics.sh --create --zookeeper hadoop01:2181 --replication-factor 1 --partitions 3 --topic streaming_topic

查看所有的topic
./kafka-topics.sh --list --zookeeper hadoop01:2181

查看某个具体的topic
./kafka-topics.sh --describe --topic streaming_topic --zookeeper hadoop:2181 

删除某个topic
./kafka-topics.sh --delete --zookeeper hadoop:2181 --topic streaming_topic

定义一个kafka的生产者来发送消息(命令行)
./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic hello

再定义一个kafka的消费者, 并启动(阻塞)
./kafka-console-consumer.sh --zookeeper hadoop01:2181 --topic streaming_topic --from-beginning

server.properties中
broker.id 如果是一个集群, 则每个实例的broker.id是个唯一的值

解压kafka后, 其自带zookeeper
nohup ./bin/zookeeper-server-start.sh config/zookeeper.properties &
vim nohup.out


Kafka: 消息系统
	消息中间件：生产者和消费者

	妈妈：生产者
	你：消费者
	馒头：数据流、消息

		正常情况下： 生产一个  消费一个
		其他情况：  
			一直生产，你吃到某一个馒头时，你卡主(机器故障)， 馒头就丢失了
			一直生产，做馒头速度快，你吃来不及，馒头也就丢失了

		拿个碗/篮子，馒头做好以后先放到篮子里，你要吃的时候去篮子里面取出来吃

	篮子/框： Kafka
		当篮子满了，馒头就装不下了，咋办？ 
		多准备几个篮子 === Kafka的扩容

Kafka架构
	producer：生产者，就是生产馒头(老妈)
	consumer：消费者，就是吃馒头的(你)
	broker：篮子
	topic：主题，给在一个篮子里的不同馒头带一个标签，
		topic-a的馒头是给你吃的，topic-b的馒头是给你弟弟吃

单节点单broker的部署及使用

    修改配置文件:
        $KAFKA_HOME/config/server.properties: 每个server.properties文件里只有一个broker.id=0, 也就是唯一对应一个kafka节点
            broker.id=0 每个kafka的唯一标识
            listeners
            host.name
            log.dirs
            zookeeper.connect

单节点多broker
	一个server.properties就相当于一个kafka节点

    server-1.properties
        log.dirs=/home/hadoop/app/tmp/kafka-logs-1
        listeners=PLAINTEXT://:9093
        broker.id=1

    server-2.properties
        log.dirs=/home/hadoop/app/tmp/kafka-logs-2
        listeners=PLAINTEXT://:9094
        broker.id=2

    server-3.properties
        log.dirs=/home/hadoop/app/tmp/kafka-logs-3
        listeners=PLAINTEXT://:9095
        broker.id=3

    kafka-server-start.sh -daemon $KAFKA_HOME/config/server-1.properties &
    kafka-server-start.sh -daemon $KAFKA_HOME/config/server-2.properties &
    kafka-server-start.sh -daemon $KAFKA_HOME/config/server-3.properties &

    因为有三个kafka节点, 所以创建一个分区, 三个副本
    kafka-topics.sh --create --zookeeper hadoop000:2181 --replication-factor 3 --partitions 1 --topic my-replicated-topic

    生产
        kafka-console-producer.sh --broker-list hadoop000:9093,hadoop000:9094,hadoop000:9095 --topic my-replicated-topic

    消费
        kafka-console-consumer.sh --zookeeper hadoop000:2181 --topic my-replicated-topic

    查看topic的详细信息
        kafka-topics.sh --describe --zookeeper hadoop000:2181 --topic my-replicated-topic
